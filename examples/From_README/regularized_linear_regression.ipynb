{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example from README\n",
    "Let's go through a quick example of how we can use slune ... first let's define a model that we want to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Regularized Linear Regression without using external libraries\n",
    "\n",
    "# Function to compute the mean of a list\n",
    "def mean(values):\n",
    "    return sum(values) / float(len(values))\n",
    "\n",
    "# Function to compute the covariance between two lists\n",
    "def covariance(x, mean_x, y, mean_y):\n",
    "    covar = 0.0\n",
    "    for i in range(len(x)):\n",
    "        covar += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "    return covar\n",
    "\n",
    "# Function to compute the variance of a list\n",
    "def variance(values, mean):\n",
    "    return sum((x - mean) ** 2 for x in values)\n",
    "\n",
    "# Function to compute coefficients for a simple regularized linear regression\n",
    "def coefficients_regularized(x, y, alpha):\n",
    "    mean_x, mean_y = mean(x), mean(y)\n",
    "    var_x = variance(x, mean_x)\n",
    "    covar = covariance(x, mean_x, y, mean_y)\n",
    "    b1 = (covar + alpha * var_x) / (var_x + alpha)\n",
    "    b0 = mean_y - b1 * mean_x\n",
    "    return b0, b1\n",
    "\n",
    "# Function to make predictions with a simple regularized linear regression model\n",
    "def linear_regression_regularized(train_X, train_y, test_X, alpha):\n",
    "    b0, b1 = coefficients_regularized(train_X, train_y, alpha)\n",
    "    predictions = [b0 + b1 * x for x in test_X]\n",
    "    return predictions\n",
    "\n",
    "# ------------------\n",
    "# The above is code for a simple normalized linear regression model that we want to train.\n",
    "# Now let's fit the model and use slune to save how well our model performs!\n",
    "# ------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # First let's load in the value for the regularization parameter alpha that has been passed to this script from the command line. We will use the slune helper function lsargs to do this. \n",
    "    # lsargs returns a tuple of the python path and a list of arguments passed to the script. We can then use this to get the alpha value.\n",
    "    from slune import lsargs\n",
    "    python_path, args = lsargs()\n",
    "    alpha = float(args[0])\n",
    "\n",
    "    # Mock training dataset, function is y = 1 + 1 * x\n",
    "    X = [1, 2, 3, 4, 5]\n",
    "    y = [2, 3, 4, 5, 6]\n",
    "\n",
    "    # Mock test dataset\n",
    "    test_X = [6, 7, 8]\n",
    "    test_y = [7, 8, 9]\n",
    "    test_predictions = linear_regression_regularized(X, y, test_X, alpha)\n",
    "\n",
    "    # First let's load in a function that we can use to get a saver object that uses the default method of logging. The saving will be coordinated by a csv saver object which saves and reads results from csv files stored in a hierarchy of directories.\n",
    "    from slune import get_csv_saver\n",
    "    csv_saver = get_csv_saver(params = args)\n",
    "\n",
    "    # Let's now calculate the mean squared error of our predictions and log it!\n",
    "    mse = mean((test_y[i] - test_predictions[i])**2 for i in range(len(test_y)))\n",
    "    csv_saver.log({'mse': mse})\n",
    "\n",
    "    # Let's now save our logged results!\n",
    "    csv_saver.save_collated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, export the above code chunk to a python script in the same directory as this notebook and name it model.py. And make sure you are on a machine that has SLURM and that you have installed slune (check the README for instructions on how to install slune). Last thing, copy the file named 'cpu_template.sh' into the same directory as this notebook and modify it so that the SBATCH directives are as you would like.\n",
    "\n",
    "Now let's write some code that will submit some jobs to train our model using different hyperparameters!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now load in a function that will coordinate our search! We're going to do a grid search.\n",
    "# SearcherGrid is the class we can use to coordinate a grid search. We pass it a dictionary of hyperparameters and the values we want to try for each hyperparameter. We also pass it the number of runs we want to do for each combination of hyperparameters.\n",
    "from slune.searchers import SearcherGrid\n",
    "grid_searcher = SearcherGrid({'alpha' : [0.25, 0.5, 0.75]}, runs = 1)\n",
    "\n",
    "# Let's now import a function which will submit a job for our model, the script_path specifies the path to the script that contains the model we want to train. The template_path specifies the path to the template script that we want to specify the job with, cargs is a list of constant arguments we want to pass to the script for each tuning. \n",
    "# We set saver to None as we don't want to not run jobs if we have already run them before.\n",
    "from slune import sbatchit\n",
    "script_path = 'model.py'\n",
    "template_path = 'template.sh'\n",
    "sbatchit(script_path, template_path, grid_searcher, cargs=[], saver=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've submitted our jobs we will wait for them to finish 🕛🕐🕑🕒🕓🕔🕕🕖🕗🕘🕙🕚🕛, now that they are finished we can read the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slune import get_csv_saver\n",
    "csv_saver = get_csv_saver(params = None)\n",
    "params, value = csv_saver.read(params = [], metric_name = 'mse', select_by ='min')\n",
    "print(f'Best hyperparameters: {params}')\n",
    "print(f'Their MSE: {value}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
